{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOnIysh0YHCa"
   },
   "source": [
    "# Google Colab\n",
    "Wir nutzen Colab, weil es eine einfache Programmieroberflaeche mit den benoetigten Bibliotheken bietet. Ausserdem gibt es GPUs kostenlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jm6TP7GnYQnu",
    "outputId": "3863bdca-b8a1-41d5-a8fe-d9c2e6b0b31a"
   },
   "outputs": [],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhVIINKGfCiI"
   },
   "source": [
    "# Problemstellung\n",
    "\n",
    "Welches Problem wollen wir lösen?\n",
    "Die vielleicht wichtigste Frage beim Entwicklen eines Machine Learning Models ist: \n",
    "\n",
    "- Was ist das Problem?\n",
    "- Was sind die Inputs?\n",
    "- Was soll vorhergesagt werden?\n",
    "- Was für eine Art Problem ist das?\n",
    "  - Klassifizierung?\n",
    "  - Regression?\n",
    "  - Semantische Segmentierung?\n",
    "  - Instanzsegmentierung?\n",
    "  - Objekt-Erkennung?\n",
    "  - Generierung?\n",
    "  - ...?\n",
    "- Wie messen wir ob unser Model gut ist?\n",
    "  - Klassifizierung:\n",
    "    - Genauigkeit\n",
    "    - Sensitivitaet\n",
    "    - Spezifizitaet\n",
    "    - Konfusionsmatrix\n",
    "    - F1-score\n",
    "  - Regression:\n",
    "    - Mean-squared error (MSE)\n",
    "    - Mean absolute error (MAE)\n",
    "  - Segmentierung:\n",
    "    - Intersection-over-union (IoU)\n",
    "    - Dice score (DSC)\n",
    "  - und viele mehr...\n",
    "\n",
    "## Ziffernerkennung\n",
    "\n",
    "Was:\n",
    "In diesem Beispiel wollen wir Checks automatisch auslesen:\n",
    "\n",
    "![](https://blog.filestack.com/wp-content/uploads/2019/07/check-processing-1.png)\n",
    "\n",
    "Nehmen wir mal an, dass wir schon wissen wo die Ziffern in das Datumsfeld und das Geldmenge-Feld eingetragen sind. Jetzt muessen wir die einzelnen Bilder von Ziffern in die jeweiligen Ziffern uebertragen:\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*hVdoiW35FXUE-fZ0HI30Tw.jpeg)\n",
    "\n",
    "Inputs: Bilder von Ziffern: $x$\n",
    "\n",
    "Vorhersage: Wir sagen vorher, welche Ziffer ${0, 1, 2, 3, 4, 5, 6, 7, 8, 9}$ gesehen wurde.\n",
    "\n",
    "Art des Problems: Klassifizierung in eine der 10 Ziffern - $p(\\hat{y}=y\\mid x)$\n",
    "\n",
    "Testen: Wir messen wie viele Ziffern richtig vorhergesagt wurden - die \"Genauigkeit\" (= accuracy) unseres Klassifizierers:\n",
    "$$acc = \\frac{1}{n}\\sum_{i=1}^{n} [(\\arg \\max_{\\hat{y}}p(\\hat{y}\\mid x)) == y]$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJymEgMybWUM"
   },
   "source": [
    "# Datensammlung\n",
    "\n",
    "So, wo bekommen wir die Daten her? In echten Projekten wird einem teilweise ein Projekt vorgegeben und dann auch die Daten mitgeliefert. Manchmal denkt man sich aber selbst ein Projekt aus und muss selbst Daten sammeln oder suchen:\n",
    "- https://www.tensorflow.org/datasets\n",
    "- https://datasetsearch.research.google.com\n",
    "- https://www.kaggle.com/datasets\n",
    "- https://grand-challenge.org/challenges/\n",
    "\n",
    "## MNIST\n",
    "Wir haben Glueck -- der MNIST Datensatz: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/MnistExamples.png/320px-MnistExamples.png)\n",
    "\n",
    "Hier haben wir 60.000 Training- und 10.000 Testbilder von Ziffern 0-9 und deren Klassenangehoerigkeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "09b7a3ba96c44778af268d68bdb434da",
      "82ec29f6d55c40fbb11ff7aa2f17c848",
      "394cdfea617042678ec7f693598ecb66",
      "6f8bf9ba848a4f13b371e15d4dc7198e",
      "4e93a95d0abb487bb8a8adb2e3bcbdee",
      "9fb2b652e6924149a7b7cafaa54d63f2",
      "33754859902747f6beb5377440f6b516",
      "6eb1ff03f9854b0ea675ea4e09ca3435",
      "a625875a81bc4a6cbf8677391593e424",
      "65bd360a7ff64744afc22b2884fb27c6",
      "6d9ff0ebb9d04c50ba76dfb247d7d2c8"
     ]
    },
    "id": "uKWL5GohkvI8",
    "outputId": "8faded4c-d339-46ab-b82d-b30c9c4d6286"
   },
   "outputs": [],
   "source": [
    "# Wir koennen die Daten mit Tensorflow Datasets laden:\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(ds_train, ds_valid, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train[:70%]', 'train[70%:]', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5O3nZ_3obdhS"
   },
   "source": [
    "# Erste Datenanalyse\n",
    "\n",
    "Als erstes sollten wir uns mit den Daten vertraut machen und einige Fragen beantworten:\n",
    "- Wie sehen die Daten aus?\n",
    "- Welches Format haben sie?\n",
    "  - Wie groß sind die Bilder?\n",
    "  - Welche Werte nehmen die Pixel an?\n",
    "- Was sind die Statistiken:\n",
    "  - Fuer Klassifizierungen, was ist die Klassenverteilung?\n",
    "  - Fuer Regressionen, was ist die Verteilung der Werte? Was ist der Mittelwert, die Standardabweichung?\n",
    "\n",
    "Fuer bekannte Datensaetze kann man auch https://knowyourdata-tfds.withgoogle.com benutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EX_R0lPfbsxr",
    "outputId": "8c25534c-b72c-4f2f-9317-e7eabd05a0cf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Schauen wir uns ein paar Daten an.\n",
    "# Dazu nutzen wir tfds.visualization.show_examples:\n",
    "help(tfds.visualization.show_examples)\n",
    "\n",
    "# Das benutzt matplotlib zum anzeigen der Bilder.\n",
    "# https://matplotlib.org\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Und numpy brauchen wir spaeter um mit Matrizen und Vektoren zu arbeiten.\n",
    "import numpy as np\n",
    "\n",
    "tfds.visualization.show_examples(ds_train, ds_info)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Die Beschriftungen sind \"Klassenname (Klassen-ID)\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj-AuO5KmKHE"
   },
   "source": [
    "Wie wir hier sehen sind die Labels schon in Zahlen gespeichert und einfach zu verwenden. In anderen Datensaetzen wollen wir aber keine Ziffern klassifizieren sondern, z.B. Hunde und Katzen auseinander halten wollen. Dazu muessen wir diese Klassen auf numerische Kategorien umwandeln und numerieren dazu dann einfach die Klassen von $0-n$, wobei $n$ die Anzahl der Klassen ist. In den Datensaetzen die wir hier laden, wird dies automatisch gemacht. Falls ihr selbst Datensaetze gestaltet muesstet ihr diese Umwandlung selbst gestalten. \n",
    "\n",
    "Die Bilder sehen schon gut aus! Aber wie gross sind sie und wie steht es um die anderen Fragen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgFx_wEUmjdY",
    "outputId": "1707b181-a27e-4ad6-a04e-e7498d03d36a"
   },
   "outputs": [],
   "source": [
    "# ds_info enthaelt eine \"Features\"-Beschreibung wo man die Form der Bilder findet:\n",
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "n1vMzWDpmyk9",
    "outputId": "74e5735d-5a86-46bc-e693-139de914dec3"
   },
   "outputs": [],
   "source": [
    "# Hier laden wir den Datensatz in ein Pandas DataFrame:\n",
    "# ACHTUNG! Das funktioniert, weil MNIST recht klein ist - fuer groessere\n",
    "# Datensaetze sollte man nur Teile laden.\n",
    "# Deswegen dauert das auch ein Weilchen.\n",
    "# https://pandas.pydata.org\n",
    "import pandas as pd\n",
    "\n",
    "df = tfds.as_dataframe(ds_train, ds_info)\n",
    "\n",
    "# Pandas DataFrame sind Tabellen, wo wir eine Spalte mit dem Bild und eine mit\n",
    "# dem Label haben:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "RtIpOSYppYKu",
    "outputId": "d0981fab-c4f7-4ea3-f2fb-50eab4273434"
   },
   "outputs": [],
   "source": [
    "# Wir koennen einzelne Bilder darstellen:\n",
    "plt.imshow(df['image'][0].reshape((28, 28)))\n",
    "# Wir muessen das Bild von (28, 28, 1) in (28, 28) unformen,\n",
    "# da matplotlib das (..., ..., 1) nicht als Schwarz-Weiss versteht.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4wRKWWXqpEc",
    "outputId": "74f236bf-a480-4b8d-cf43-081c3e2e99d5"
   },
   "outputs": [],
   "source": [
    "# Und uns anschauen, welche Werte die Bilder annehmen:\n",
    "print(f\"Min: {df['image'][0].min()} - Max: {df['image'][0].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "0fzd40Ahpt97",
    "outputId": "a63a8dc8-b883-4a28-d6c0-f5db62dd795c"
   },
   "outputs": [],
   "source": [
    "# Wir koennen auch die Statistiken der Labels darstellen.\n",
    "# Hierfuer ist Seaborn sehr nuetzlich:\n",
    "# https://seaborn.pydata.org\n",
    "import seaborn as sns\n",
    "sns.countplot(data=df, x='label')\n",
    "plt.show()\n",
    "\n",
    "# Wir sehen, dass die Klassen halbwegs gleichmaessig verteilt sind - das ist\n",
    "# relativ Wichtig fuer die Analyse spaeter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sthl2ZX-cFb7"
   },
   "source": [
    "# Bauen eines ersten Models\n",
    "\n",
    "Jetzt, wo wir die Daten etwas verstanden haben, koennen wir unser erstes Model bauen!\n",
    "\n",
    "Aber was optimieren wir eigentlich? Die Bernoulli-Likelihood ist nur fuer 2 Klassen gedacht...\n",
    "\n",
    "Fuer mehrere Klassen benutzen wir die softmax-Funktion:\n",
    "$$p(\\hat{y}=i) = softmax(h)_i = \\frac{exp(h_i)}{\\sum_{j=1}^{k}exp(h_j))}$$\n",
    "\n",
    "und die Kategorische (Categorical)-Likelihood:\n",
    "$$p(y) = [y=1] * \\pi_1 + \\dots + [y=k] * \\pi_k$$\n",
    "Damit kann man die Likelihood unserer Messwerte berechnen als\n",
    "$$\\Rightarrow p(\\hat{y}=y)=softmax(h)_y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfcOUORssn6C"
   },
   "source": [
    "## Datenvorbereitung\n",
    "\n",
    "Wie wir gesehen haben, sind die Bildpixel im Bereich $[0, 255]$. Hier ist es hilfreich die Werte in den Bereich $[0, 1]$ oder $[-1, 1]$ zu konvertieren. Dies hilft, damit die Gewichte des neuronalen Netzes nicht so groß sein müssen. Dies wird angewandt mit `dataset.map(normalisierer)`.\n",
    "\n",
    "Zusaetzlich speichern wir die geänderten Bilder im Arbeitsspeicher (`dataset.cache`), nutzt eine zufaellige Reihenfolge fuer die Bilder im Trainingsset (`dataset.shuffle`), und baut Batches mit Groesse 128 (`dataset.batch`). Zum Schluss nutzen wir noch \"prefetching\" (`dataset.prefetch`) um mehrere Batches im Speicher zu halten damit die spaeteren Berechnungen nicht darauf warten muessen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6icTwc62czVi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalisiert die Bilder von [0, 255] zu [0, 1] und konvertiert die Datentypen `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(int(ds_info.splits['train'].num_examples * 0.7))\n",
    "ds_train = ds_train.batch(128)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_valid = ds_valid.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_valid = ds_valid.cache()\n",
    "ds_valid = ds_valid.batch(128)\n",
    "ds_valid = ds_valid.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.batch(128)\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2d_phMdIsp_y"
   },
   "source": [
    "## Modelerstellung\n",
    "\n",
    "Jetzt kommen wir endlich zu dem Punkt an dem wir unser Model bauen! Dies besteht aus dem eigentlichen neuronalen Netz und der Loss-Funktion um zu bestimmen wie gut unser Model ist.\n",
    "\n",
    "Wir benutzen die Keras-Bibliothek um die Modelle zu trainieren. Bei Keras gehoert auch der Optimierer mit in das Modell - Hier benutzen wir direkt den Adam-Optimierer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzRoextosr5Q"
   },
   "outputs": [],
   "source": [
    "# Unser Model ist einfach die Aneinanderschachtelung von 2 Linearen-Layern mit\n",
    "# einer ReLU-Funktion dazwischen. Hier fangen wir damit an das Bild von einer \n",
    "# 28x28 Matrix in einen 784 Vektor umzuformen (Flatten) und fuegen dann die\n",
    "# Linear (hier Dense) Layers hinzu. Der \"Hidden Layer\" hat 128 Neuronen - das\n",
    "# sind 784 x 128 Gewichte. Das letze Layer hat dann 128x10 Gewichte\n",
    "# mit 10 Ausgangsneuronen, die die Wahrscheinlichkeiten der verschiedenen\n",
    "# Klassen modellieren.\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buH9Ezv44mXR"
   },
   "outputs": [],
   "source": [
    "# Anschliessend stellen wir unser Model fertig, indem wir einen Optimierer\n",
    "# (Adam), die Loss-Funktion und Metriken, die wir messen wollen, festlegen.\n",
    "# Hier nutzen wir die `SparseCategoricalCrossentropy` Loss-Funktion. Diese ist\n",
    "# eine Kategorische (Categorical) Likelihood - sie ist \"Sparse\", weil die\n",
    "# Labels als Klassen-ID (0-9) angegeben anstatt als Wahrscheinlichkeitsvektoren:\n",
    "# 1 = [1, 0, 0, ..., 0], 2 = [0, 1, 0, 0, ..., 0].\n",
    "# Ausserdem nutzen wir logits - dies bedeutet, dass unser Netzwerk den Input in\n",
    "# den Softmax ausgibt anstatt die Wahrscheinlichkeiten nach dem Softmax.\n",
    "# Als Metriken wollen wir einfach nur die Genauigkeit (Accuracy) messen.\n",
    "# Fuer den Adam-Optimierer nutzen wir eine learning rate von 0.001.\n",
    "\n",
    "# Uebrigens - `compile` legt auch die ersten \"weights\" fest.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCBqFL-ist5n"
   },
   "source": [
    "## Modeltraining\n",
    "\n",
    "Das Model muss jetzt nur noch trainiert werden und dann waeren wir auch schon fertig. Keras macht uns das sehr einfach -- wir muessen nur `model.fit` aufrufen und die Daten festlegen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4opLzA-syJX",
    "outputId": "7b9a2634-2219-49f7-e5ab-0bd165bc325e"
   },
   "outputs": [],
   "source": [
    "# Hier nutzen wir `ds_train` als Trainingsdatensatz, trainieren fuer 10 Epochen\n",
    "# und nutzen `ds_valid` als Validierungsdatensatz.\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=15,\n",
    "    validation_data=ds_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Dw6rUYAczt4"
   },
   "source": [
    "# Analyse der Ergebnisse\n",
    "\n",
    "Nachdem wir jetzt unser Modell trainiert haben koennen wir das Model auch auf dem Testdaten ausprobieren. Hierzu bietet Keras wieder eine einfache Funktion: `model.evaluate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOLNbANrdBbU",
    "outputId": "4d4844b1-e7ca-4a1a-82aa-c5960b3d03a9"
   },
   "outputs": [],
   "source": [
    "print(model.evaluate(ds_train))\n",
    "print(model.evaluate(ds_valid))\n",
    "print(model.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-Rb6-AhHJ_g"
   },
   "source": [
    "Wir sehen hier schon, dass wir 97% Genauigkeit erreichen koennen - welche Zahlen bekommen wir aber besonders gut hin und welche weniger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "id": "5NgX1Do3INtH",
    "outputId": "85b858e8-8bd3-4159-92ea-9fc7c26a0b0d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Hier benutzen wir sklearn um Konfusionsmatrizen zu erstellen und generelle\n",
    "# Berichte zu der Performance zu verfassen.\n",
    "# https://scikit-learn.org/stable/index.html\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Hier benutzen wir `model.predict` um die Vorhersagen zu erhalten.\n",
    "# Leider haben unsere Optimierungen am Datensatz, dass wir batchen und prefetchen\n",
    "# dazu gefuehrt dass wir die Reihenfolge der Daten nicht mehr kennen. Also speichern\n",
    "# wir die Eingabewerte beim Vorhersagen:\n",
    "\n",
    "y_prob = []  # Hier speichern wir die Modelvorhersagen\n",
    "y_true = []  # Hier speichern wir die echten Labels\n",
    "x_input = [] # Hier speichern wir die Bilder\n",
    "\n",
    "# Wir sagen die Ergebnisse unseres Modells auf den Validierungsdaten her.\n",
    "for image_batch, label_batch in ds_valid:\n",
    "   # Speichere die Eingaben\n",
    "   x_input.append(image_batch.numpy())\n",
    "   y_true.append(label_batch.numpy())\n",
    "   # Berechne die Vorhersagen\n",
    "   preds = model.predict(image_batch)\n",
    "   # Hier nutzen wir den Softmax um die Wahrscheinlichkeiten zu berechnen und \n",
    "   # speichern diese in y_prob.\n",
    "   y_prob.append(tf.nn.softmax(preds).numpy())\n",
    "\n",
    "# Zum Schluss wandeln wir unseren Speicher noch in Matrizen um:\n",
    "x_input = np.concatenate(x_input)\n",
    "y_true = np.concatenate(y_true)\n",
    "y_prob = np.concatenate(y_prob)\n",
    "\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# sklearn bietet eine einfach Funktion fuer Konfusionsmatrizen:\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# die wir nur noch darstellen muessen.\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\": 8}, cmap=\"YlGnBu\") # font size\n",
    "plt.show()\n",
    "\n",
    "# Und dann koennen wir uns einen Bericht ueber die Ergebnisse der einzelnen\n",
    "# Klassen ansehen.\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bmn6f_oPHLw"
   },
   "source": [
    "Um das ganze uns noch genauer anzuschauen koennen wir versuchen zu verstehen weshalb manche Ziffern falsch kategorisiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vTPTK9WGPCPK",
    "outputId": "b6e3f563-cef5-4a7e-b08a-dcdd913d2447"
   },
   "outputs": [],
   "source": [
    "y_prob_class = y_prob[np.arange(len(y_prob)), y_true]\n",
    "\n",
    "low_prob_samples = np.argsort(y_prob_class)\n",
    "\n",
    "for idx in low_prob_samples[:5]:\n",
    "  pred_prob = y_prob[idx]\n",
    "  pred_label = np.argmax(pred_prob)\n",
    "  print(f'[{idx}] Vorhersage:\\n{pred_prob}\\n-> {pred_label} -- Echt: {y_true[idx]}')\n",
    "  plt.imshow(x_input[idx].reshape(28, 28))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-alM7fXUYqh"
   },
   "source": [
    "Hier haben wir gesehen, dass unser Modell schon sehr gut ist und die einzigen Fehler eigentlich Ziffern sind, die schwer zu erkennen sind. Manchmal kann man damit aber auch Fehler im Datensatz finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQ2sgIxHdDtq"
   },
   "source": [
    "# Verbessern des Models\n",
    "\n",
    "Wie wir gesehen haben, hat dieses Model noch einige Probleme. Stattdessen können wir ein Convolutional Neural Network (CNN) bauen, was besser fuer Bilder ist.\n",
    "\n",
    "Ausserdem benutzen wir Max-Pooling um die Groesse der Zwischenschritte zu verkleinern und Speicherplatz zu sparen:\n",
    "![](https://cs231n.github.io/assets/cnn/maxpool.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxDOk5BsdE6v"
   },
   "outputs": [],
   "source": [
    "# Hier nutzen wir 2 convolutional Layer mit ReLU-Aktivierung\n",
    "# und Max-Pooling danach.\n",
    "# Nach den CNN-Layern, aendern wir wieder die Form in einen Vektor (`flatten`)\n",
    "# und haben noch zwei \"normale\" Layer.\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(8, 3, activation='relu',\n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "  tf.keras.layers.MaxPool2D(),\n",
    "  tf.keras.layers.Conv2D(16, 3, activation='relu',\n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "  tf.keras.layers.MaxPool2D(),\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu',\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(1e-3)),\n",
    "  tf.keras.layers.Dense(10, kernel_regularizer=tf.keras.regularizers.l2(1e-3))\n",
    "])\n",
    "\n",
    "# Der Rest ist das Gleiche wie vorher!\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duHAEJrIU5DL",
    "outputId": "03ba1eb0-ccb8-48d7-aaef-30af2c07ca42"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    validation_data=ds_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-dv9dZIU9iv",
    "outputId": "2c92f557-c034-4877-bf7d-0399c4ecd595"
   },
   "outputs": [],
   "source": [
    "# Und wir sehen, dass unsere Validierungs- und Testergebnisse besser sind\n",
    "# und wir nicht mehr overfitten:\n",
    "print(model.evaluate(ds_train))\n",
    "print(model.evaluate(ds_valid))\n",
    "print(model.evaluate(ds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsBY-peqV4hW"
   },
   "source": [
    "# Keras Modelle\n",
    "Keras bietet aber auch schon vorgefertigte Modelle an, die veroeffentlicht wurden: https://keras.io/api/applications/\n",
    "\n",
    "Hier koennen wir zum Beispiel ein ResNet (residual network mit diesen Sprungverbindungen) einfach laden und benutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVgRKTDWVuYR"
   },
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input((28, 28, 1))\n",
    "padded = tf.keras.layers.ZeroPadding2D(padding=(2, 2))(input_layer)\n",
    "model = tf.keras.applications.ResNet50(\n",
    "      include_top=True,\n",
    "      input_tensor=padded,\n",
    "      pooling=\"avg\",\n",
    "      weights=None,\n",
    "      classes=10,\n",
    "  )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLf04htNW-Rk",
    "outputId": "6b3ea5ab-2eac-44c0-c896-e235edb31eaf"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=10,\n",
    "    validation_data=ds_valid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8HyYVtiZjS_",
    "outputId": "7e2f4f9f-c7e1-4fba-c016-845f5900db74"
   },
   "outputs": [],
   "source": [
    "# Der MNIST Datensatz ist relativ klein, deswegen sehen wir keinen grossen\n",
    "# Vorteil mit diesem groesseren Model! Ausserdem muessten wir vmtl laenger\n",
    "# trainieren...\n",
    "print(model.evaluate(ds_train))\n",
    "print(model.evaluate(ds_valid))\n",
    "print(model.evaluate(ds_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Entwicklung eines ML Models: Anfang bis Ende.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09b7a3ba96c44778af268d68bdb434da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_394cdfea617042678ec7f693598ecb66",
       "IPY_MODEL_6f8bf9ba848a4f13b371e15d4dc7198e",
       "IPY_MODEL_4e93a95d0abb487bb8a8adb2e3bcbdee"
      ],
      "layout": "IPY_MODEL_82ec29f6d55c40fbb11ff7aa2f17c848"
     }
    },
    "33754859902747f6beb5377440f6b516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "394cdfea617042678ec7f693598ecb66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33754859902747f6beb5377440f6b516",
      "placeholder": "​",
      "style": "IPY_MODEL_9fb2b652e6924149a7b7cafaa54d63f2",
      "value": "Dl Completed...: 100%"
     }
    },
    "4e93a95d0abb487bb8a8adb2e3bcbdee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d9ff0ebb9d04c50ba76dfb247d7d2c8",
      "placeholder": "​",
      "style": "IPY_MODEL_65bd360a7ff64744afc22b2884fb27c6",
      "value": " 4/4 [00:02&lt;00:00,  1.36 file/s]"
     }
    },
    "65bd360a7ff64744afc22b2884fb27c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d9ff0ebb9d04c50ba76dfb247d7d2c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6eb1ff03f9854b0ea675ea4e09ca3435": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6f8bf9ba848a4f13b371e15d4dc7198e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a625875a81bc4a6cbf8677391593e424",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6eb1ff03f9854b0ea675ea4e09ca3435",
      "value": 4
     }
    },
    "82ec29f6d55c40fbb11ff7aa2f17c848": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fb2b652e6924149a7b7cafaa54d63f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a625875a81bc4a6cbf8677391593e424": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
